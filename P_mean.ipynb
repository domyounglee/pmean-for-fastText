{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "import json\n",
    "import gensim\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format('../DeepLearning/wordembedding/pretrained/w2v_vectors.bin', binary=True,unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from p_mean import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': (<function p_mean.<lambda>(word_embeddings)>,\n",
       "  <function p_mean.<lambda>(embeddings_size)>),\n",
       " 'max': (<function p_mean.<lambda>(word_embeddings)>,\n",
       "  <function p_mean.<lambda>(embeddings_size)>),\n",
       " 'min': (<function p_mean.<lambda>(word_embeddings)>,\n",
       "  <function p_mean.<lambda>(embeddings_size)>),\n",
       " 'p_mean_2': (<function p_mean.<lambda>(word_embeddings)>,\n",
       "  <function p_mean.<lambda>(embeddings_size)>),\n",
       " 'p_mean_3': (<function p_mean.<lambda>(word_embeddings)>,\n",
       "  <function p_mean.<lambda>(embeddings_size)>)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordembeddings = []\n",
    "for word in query_sent.split(\" \"):\n",
    "    wordembeddings.append(np.squeeze(normalize(w2v[word].reshape(1,-1))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_embs = []\n",
    "concat_embs2 = []\n",
    "for o in ['mean','max']:\n",
    "    concat_embs += operations[o][0](wordembeddings)\n",
    "    concat_embs2.append(operations[o][0](wordembeddings))\n",
    "\n",
    "    sentence_embedding = np.concatenate(concat_embs, axis=0)\n",
    "    print(np.shape(sentence_embedding))\n",
    "    print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
